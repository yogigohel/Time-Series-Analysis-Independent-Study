**Definition 1.6: Strictly Stationary Time Series**
> A strictly stationary time series is one for which the probabilistic behavior of every collection of values $\{x_{t_1},...,x_{t_k}\}$ is identical to that of the time shifted set $\{x_{t_1+h},...,x_{t_k+h}\}$.
> 
> This would mean $\Pr\{x_{t_1} \leq c_1, ..., x_{t_k} \leq c_k\} = \Pr\{x_{t_1+h} \leq c_1, ..., x_{t_k+h} \leq c_k\}$ for all $k$, all time points $t_1, ..., t_k$, all numbers $c_1, ..., c_k$, and all time shifts $h=\pm 0,1,...$.
> 
> If a time series is strictly stationary, then all of the multivariate distribution functions for subsets of variables must agree with their counterparts in the shifted set for all values of the shift parameter $h$.
> > Example: When $k=2$, we can say $\Pr\{x_s\leq c_1, s_t\leq c_2\}=\Pr\{x_{s+h}\leq c_1, x_{t+h}\leq c_2\}$ for any $s,t$ and shift $h$. Also, if the variance exists here, then the autocovariance function of the series $x_t$ satisfies $\gamma(s,t)=\gamma(s+h,t+h)$ for all $s,t,h$. (Basically the autocovariance only depends on the time difference between $s$ and $t$, not their actually values).

**Definition 1.7: Weakly Stationary Time Series**
> A weakly stationary time series, $x_t$, is a finite variance process such that
> > 1.) The mean value function, $\mu_t$, is constant and does not depend on time $t$ and
> > 2.) The autocovariance function, $\gamma(s, t)$, depends only on the difference $|s-t|$ and not the actual values of $s$ and $t$.
> 
> We use the term stationary to mean weakly stationary for the rest of the text.
> 
> Stationarity requires regularity in the mean and autocorrelation functions so that these quantities (at least) may be estimated by averaging
> 
> A strictly stationary time series with finite variance is stationary.



